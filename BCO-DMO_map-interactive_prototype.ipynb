{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCO-DMO Knowledge Graph Data Exploration Prototype\n",
    "This is a prototype demonstrating how python can be used to interactively explore oceanographic data within the BCO-DMO Knowledge Graph. This demonstration was developed for SciPy 2020. \n",
    "\n",
    "**WARNING** This is just a prototype and will likely be updated (or abandoned ¯\\\\_(ツ)_/¯). In addition, the BCO-DMO Knowledge Graph is also under construction, so stability of this prototype is far from guaranteed. This is mainly just an example of how we might leverage the Knowledge Graph to facilitate interactive exploration of oceanographic data. Hope to have some amazing (and stable) tools for exploration of the Graph in the future. Brutal honesty moment: This tool which was just intended for a viz example has been great for revealing some issues with tagging of data in the Graph -- side bonus for us at BCO-DMO so we can fix these, but this does result in some issues visualizing some datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING \\#2:** Some of the datasets within BCO-DMO are very large. Therefore, for performance reasons, a limit on datasets displayed is set below. Feel free to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:53:42.020050Z",
     "start_time": "2020-07-08T20:53:42.016886Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_DATASET_SHOW = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:53:44.429930Z",
     "start_time": "2020-07-08T20:53:42.701924Z"
    }
   },
   "outputs": [],
   "source": [
    "from bqplot import Lines, Figure, LinearScale, DateScale, Axis\n",
    "from ipyleaflet import Map, GeoJSON, basemaps, WidgetControl, Marker, MarkerCluster\n",
    "from ipywidgets import link, HTML\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdflib\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from ipywidgets import Layout, IntText, Dropdown, Combobox, VBox, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:53:45.025157Z",
     "start_time": "2020-07-08T20:53:45.013963Z"
    }
   },
   "outputs": [],
   "source": [
    "#credit: Doug Fils\n",
    "def get_sparql_dataframe(service, query):\n",
    "    \"\"\"\n",
    "    Helper function to convert SPARQL results into a Pandas data frame.\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(service)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    result = sparql.query()\n",
    "\n",
    "    processed_results = json.load(result.response)\n",
    "    cols = processed_results['head']['vars']\n",
    "    \n",
    "    out = []\n",
    "    for row in processed_results['results']['bindings']:\n",
    "        item = []\n",
    "        for c in cols:\n",
    "            #item.append(str(row.get(c, {}).get('value')))\n",
    "            item.append(row.get(c, {}).get('value'))\n",
    "        out.append(item)\n",
    "# could simply return 'out' which is a list of lists\n",
    "    return pd.DataFrame(out, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:53:45.825566Z",
     "start_time": "2020-07-08T20:53:45.822326Z"
    }
   },
   "outputs": [],
   "source": [
    "BCODMO_SERVE = \"https://lod.bco-dmo.org/sparql\"  #BCO-DMO SPARQL Endpoint\n",
    "BCODMO_PREF = \"http://lod.bco-dmo.org/id/\"       #BCO-DMO URI prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:53:58.226223Z",
     "start_time": "2020-07-08T20:53:46.584075Z"
    }
   },
   "outputs": [],
   "source": [
    "## Paramter options\n",
    "###### Dataset Description Widget\n",
    "#SPARQL query for BCO-DMO dataset information\n",
    "masterParameterQuery = \"\"\"\n",
    "SELECT DISTINCT ?masterParamtersId ?shortDesc ?label #?datasetParameter #?url\n",
    "WHERE {\n",
    "    <http://lod.bco-dmo.org/id/parameters> ?property ?masterParamtersId .\n",
    "    ?masterParamtersId owl:deprecated \"0\"^^xsd:boolean . #remove deprecated master parameters\n",
    "    ?masterParamtersId odo:hasParameterShortDescription ?shortDesc .\n",
    "    ?masterParamtersId skos:prefLabel ?label .\n",
    "    ?datasetParameter odo:isInstanceOf ?masterParametersId .\n",
    "    ?dataset odo:storesValuesFor ?datasetParameter .\n",
    "    #Select only those master params that have depths\n",
    "    ?datasetParameter odo:isInstanceOf <http://lod.bco-dmo.org/id/parameter/808> . \n",
    "    #end\n",
    "    ?affordance schema:subjectOf ?dataset .\n",
    "    ?affordance rdf:type ?action_type .\n",
    "    ?affordance schema:target ?target .\n",
    "    ?target schema:contentType \"application/geo+json\"^^xsd:token .\n",
    "    #?target schema:url ?url .\n",
    "}\n",
    "ORDER BY ?shortDesc ?label ?masterParametersId\n",
    "\"\"\"\n",
    "df_masterParams_with_geoJson = get_sparql_dataframe(BCODMO_SERVE, masterParameterQuery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:39.876133Z",
     "start_time": "2020-07-08T20:56:39.839676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac704e6e1bd64e419988b73a049d372a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combobox(value='', continuous_update=False, description='Search Parameter:', layout=Layout(width='80%'), optio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displays dropdown selector for dataset parameters\n",
    "\n",
    "masterParamsOptions = df_masterParams_with_geoJson[\"label\"].values.tolist()\n",
    "style = {'description_width': 'initial'}\n",
    "masterParamsMenu = Combobox(\n",
    "    options=masterParamsOptions,\n",
    "    description='Search Parameter:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='80%'),\n",
    "    continuous_update=False,\n",
    "    style=style\n",
    ")\n",
    "\n",
    "###### Update Dataset Parameter Description with Menu Selection\n",
    "def handle_masterParam_change(change):\n",
    "    if change.new != change.old:\n",
    "        masterParamsMenu.value = change.new\n",
    "\n",
    "masterParamsMenu.observe(handle_masterParam_change, names='value') #observer for change       \n",
    "       \n",
    "masterParamsMenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:47.687124Z",
     "start_time": "2020-07-08T20:56:47.680026Z"
    }
   },
   "outputs": [],
   "source": [
    "parameterSelected = df_masterParams_with_geoJson[\"masterParamtersId\"].loc[df_masterParams_with_geoJson[\"label\"]\\\n",
    "                                == masterParamsMenu.value]\n",
    "parameterSelected = parameterSelected.to_string(index=False).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:50.062846Z",
     "start_time": "2020-07-08T20:56:49.063780Z"
    }
   },
   "outputs": [],
   "source": [
    "###Select Nitrite and see what happens - http://lod.bco-dmo.org/id/parameter/1192\n",
    "\n",
    "nitriteQuery = \"\"\"\n",
    "SELECT DISTINCT ?masterParam ?nanValue ?unit ?parameterName ?datasetID ?url\n",
    "WHERE {\n",
    "    VALUES ?masterParam {<\"\"\" + parameterSelected + \"\"\">}\n",
    "    ?dataset_parameter odo:isInstanceOf ?masterParam .\n",
    "    ?dataset_parameter odo:hasNoDataValue ?nanValue .\n",
    "    ?dataset_parameter odo:hasUnitOfMeasure ?nodeUnit .\n",
    "    ?nodeUnit rdf:value ?unit .\n",
    "    ?dataset_parameter skos:prefLabel ?parameterName .\n",
    "    ?dataset odo:storesValuesFor ?dataset_parameter . \n",
    "    #?dataset_parameter odo:isInstanceOf <http://lod.bco-dmo.org/id/parameter/808> .\n",
    "    ?dataset dcterms:identifier ?datasetID .\n",
    "    #check GeoJSON\n",
    "    ?affordance schema:subjectOf ?dataset .\n",
    "    ?affordance rdf:type ?action_type .\n",
    "    ?affordance schema:target ?target .\n",
    "    ?target schema:contentType \"text/csv\"^^xsd:token .\n",
    "    ?target schema:url ?url .\n",
    "}\n",
    "\"\"\"\n",
    "df_parameter = get_sparql_dataframe(BCODMO_SERVE, nitriteQuery)\n",
    "#df_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:50.810087Z",
     "start_time": "2020-07-08T20:56:50.802017Z"
    }
   },
   "outputs": [],
   "source": [
    "# All the datasets that have the target parameter\n",
    "listDataSetIDs = df_parameter[\"datasetID\"].astype(\"str\").values.tolist()\n",
    "listDataSetIDsStr = ' '.join(listDataSetIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:53.057604Z",
     "start_time": "2020-07-08T20:56:52.162731Z"
    }
   },
   "outputs": [],
   "source": [
    "nitriteDepthQuery = \"\"\"\n",
    "SELECT DISTINCT ?masterParamDepth ?nanValueDepth ?unitDepth ?col_nameDepth ?datasetID ?url\n",
    "WHERE {\n",
    "    VALUES ?datasetID {\"\"\" + listDataSetIDsStr + \"\"\"} \n",
    "    VALUES ?masterParamDepth { <http://lod.bco-dmo.org/id/parameter/808>} #808 is the parameter for Depth\n",
    "    ?dataset_parameter odo:isInstanceOf ?masterParamDepth .\n",
    "    ?dataset_parameter odo:hasNoDataValue ?nanValueDepth .\n",
    "    ?dataset_parameter odo:hasUnitOfMeasure ?nodeUnit .\n",
    "    ?nodeUnit rdf:value ?unitDepth .\n",
    "    ?dataset_parameter skos:prefLabel ?col_nameDepth .\n",
    "    ?dataset odo:storesValuesFor ?dataset_parameter . \n",
    "    #?dataset_parameter odo:isInstanceOf <http://lod.bco-dmo.org/id/parameter/808> .\n",
    "    ?dataset dcterms:identifier ?datasetID .\n",
    "    #check GeoJSON\n",
    "    ?affordance schema:subjectOf ?dataset .\n",
    "    ?affordance rdf:type ?action_type .\n",
    "    ?affordance schema:target ?target .\n",
    "    ?target schema:contentType \"text/csv\"^^xsd:token .\n",
    "    ?target schema:url ?url .\n",
    "}\n",
    "\"\"\"\n",
    "df_parameterDepth = get_sparql_dataframe(BCODMO_SERVE, nitriteDepthQuery)\n",
    "#parameterDepth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:53.981783Z",
     "start_time": "2020-07-08T20:56:53.979243Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_parameterDepth.style.set_properties(subset=['url'], **{'width': '600px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:54.857188Z",
     "start_time": "2020-07-08T20:56:54.851230Z"
    }
   },
   "outputs": [],
   "source": [
    "#Find all datasets that have the target parameter and associated depth data\n",
    "df_dataSetsWithParameterAndDepth = df_parameter.loc[df_parameter[\"datasetID\"].isin(df_parameterDepth[\"datasetID\"].unique())].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:56.413108Z",
     "start_time": "2020-07-08T20:56:56.404996Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dataSetsWithParameterAndDepth.drop_duplicates(subset=\"url\", inplace=True)\n",
    "urlTest = df_dataSetsWithParameterAndDepth[[\"url\", \"datasetID\"]].values[0:MAX_DATASET_SHOW] #limiting to 5 datasets max right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:56:57.430723Z",
     "start_time": "2020-07-08T20:56:57.419278Z"
    }
   },
   "outputs": [],
   "source": [
    "#create groupbys on specific datasets\n",
    "df_parameterDepth[\"parameterType\"] = \"depth\"\n",
    "try:\n",
    "    df_dataSetsWithParameterAndDepth = df_dataSetsWithParameterAndDepth.drop(columns=[\"index\"])\n",
    "except:\n",
    "    print(\"no column named index\")\n",
    "    \n",
    "df_dataSetsWithParameterAndDepth[\"parameterType\"] = str(masterParamsMenu.value)\n",
    "df_parameterDepth = df_parameterDepth.rename(columns={\"masterParamDepth\":\"masterParam\", \\\n",
    "                                                      \"col_nameDepth\":\"parameterName\", \\\n",
    "                                                      \"unitDepth\":\"unit\", \\\n",
    "                                                      \"nanValueDepth\":\"nanValue\"})\n",
    "df_paramsAndDepths = pd.concat([df_parameterDepth, df_dataSetsWithParameterAndDepth])\n",
    "\n",
    "\n",
    "gb_paramDepth = df_paramsAndDepths.groupby(\"datasetID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:57:40.842312Z",
     "start_time": "2020-07-08T20:56:59.113314Z"
    }
   },
   "outputs": [],
   "source": [
    "dfg_big = geopandas.GeoDataFrame(columns=['datasetID', 'geometry', 'parameterName', 'value', 'parameterType', 'unit'])\n",
    "dfg_points = geopandas.GeoDataFrame(columns=[\"datasetID\", \"geometry\"])\n",
    "\n",
    "for url, datasetID in urlTest:\n",
    "\n",
    "    #generate lists of parameters and depth dataset-specific column names    \n",
    "    subdf = gb_paramDepth.get_group(datasetID)\n",
    "    paramCols = subdf[\"parameterName\"].loc[subdf[\"parameterType\"] == masterParamsMenu.value].unique().tolist()\n",
    "    depthCols = subdf[\"parameterName\"].loc[subdf[\"parameterType\"] == \"depth\"].unique().tolist()\n",
    "    depthCols = depthCols + [\"depth\"]\n",
    "    #Adding some common nan issues -- need to update KG where there are multiple NaNs/dataset parameter\n",
    "    nanValues = subdf[\"nanValue\"].unique().tolist() + [\"n.a.\", \"nan\", \"-9999\", \"-999.0\", \"-999\", \"mix\", \"\"]# \\\n",
    "                                                      # \"bdl\", 'Below_detection_limit', 'ND', 'DNP', 'BDL']# coerce all these fun strings in float cols\n",
    "    df_units = subdf[[\"unit\", \"parameterName\"]]\n",
    "    \n",
    "    data = pd.read_csv(url, low_memory=False)\n",
    "    data = data.drop([0])\n",
    "    \n",
    "    colsKeep = [\"latitude\", \"longitude\"] + depthCols + paramCols\n",
    "    checkParamInFile = all(item in data.columns for item in colsKeep)\n",
    "    if checkParamInFile is False:\n",
    "        colsKeep = [s for s in colsKeep if s in data.columns]\n",
    "        paramCols = [s for s in paramCols if s in data.columns]\n",
    "        depthCols = [s for s in depthCols if s in data.columns]\n",
    "    #Drop dataset if latitude or longitude don't exist\n",
    "    checkCoords = all(item in data.columns for item in [\"latitude\", \"longitude\"])\n",
    "    if checkCoords is False:\n",
    "        continue\n",
    "        \n",
    "    dfg = data[colsKeep].copy() \n",
    "    dfg[\"datasetID\"] = datasetID \n",
    "    [dfg.replace(x, np.nan, inplace=True) for x in nanValues]\n",
    "    \n",
    "    #add unique subset of location points to points dataframe for mapping\n",
    "    dfg[\"longitude\"] = dfg[\"longitude\"].astype(\"float\")\n",
    "    dfg[\"latitude\"] = dfg[\"latitude\"].astype(\"float\")\n",
    "    \n",
    "    dfg_geometry = geopandas.GeoDataFrame(dfg, geometry=geopandas.points_from_xy(dfg[\"longitude\"], dfg[\"latitude\"]))\n",
    "    \n",
    "    #Drop rows that don't have data for the selected parameter\n",
    "    dfg_geometry[paramCols] = dfg_geometry[paramCols].fillna(1).apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    dfg_geometry = dfg_geometry.dropna(subset=paramCols)\n",
    "    \n",
    "    dfg_points = dfg_points.append(dfg_geometry[[\"datasetID\", \"geometry\"]].drop_duplicates())\n",
    "    \n",
    "    paramsList = paramCols + depthCols\n",
    "    dfg_melt = pd.melt(dfg_geometry, id_vars=[\"datasetID\", \"geometry\"], \\\n",
    "             value_vars=[c for c in dfg_geometry.columns if c in paramsList],\\\n",
    "            var_name='parameterName')\n",
    "    dfg_melt[\"parameterType\"] = \"depth\"\n",
    "    dfg_melt.loc[dfg_melt[\"parameterName\"].isin(paramCols), ['parameterType']] = 'parameter' \n",
    "    dfg_melt = pd.merge(dfg_melt, df_units, how=\"left\")\n",
    "    \n",
    "    dfg_big = dfg_big.append(dfg_melt)     \n",
    "\n",
    "#convert dfg_points to geoJson\n",
    "dfg_points = dfg_points.reset_index().drop(columns='index')\n",
    "point_geoJson = dfg_points.to_file(\"points.geojson\", driver='GeoJSON')\n",
    "\n",
    "with open('points.geojson', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:58:00.607224Z",
     "start_time": "2020-07-08T20:57:50.909561Z"
    }
   },
   "outputs": [],
   "source": [
    "dfp = pd.DataFrame(dfg_big) #convert to pandas dataframe to do more \n",
    "dfp[\"geometry_str\"] = dfp[\"geometry\"].astype(\"str\").str.replace(\"POINT \", \"\").str.replace(\"(\", \"\").str.replace(\")\", \"\")\n",
    "dfp[['longitude','latitude']] = dfp[\"geometry_str\"].str.split(expand=True)\n",
    "dfp[\"value\"] = dfp[\"value\"].astype(\"float\").round(2)\n",
    "dfp[\"value\"].loc[dfp[\"parameterName\"] == masterParamsMenu.value].astype(\"float\").round(0)\n",
    "\n",
    "dfp[['longitude','latitude']] = dfp[['longitude','latitude']].astype(\"float\")\n",
    "#dfp[['longitude','latitude']] = dfp[['longitude','latitude']].round(5)\n",
    "dfp[\"lon_lat\"] = dfp[\"latitude\"].astype(\"str\") + \" \" + dfp[\"longitude\"].astype(\"str\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:00:05.957590Z",
     "start_time": "2020-07-08T20:00:03.755092Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb_dfp = dfp.groupby([\"datasetID\"])    \n",
    "                                                               \n",
    "m = Map(center=(0, 0), zoom=1, basemap=basemaps.Esri.NatGeoWorldMap)\n",
    "geo_json = GeoJSON(data=data, style = {\n",
    "})\n",
    "\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "html1 = HTML('''\n",
    "    <h4>Dataset Info</h4>\n",
    "    Click on a point\n",
    "''')\n",
    "html1.layout.margin = '0px 20px 20px 20px'\n",
    "control1 = WidgetControl(widget=html1, position='bottomleft')\n",
    "\n",
    "\n",
    "def update_html(feature, **kwargs):\n",
    "    html1.value = '''\n",
    "        <b>Dataset: {}</b></br>\n",
    "        <a>https://www.bco-dmo.org/dataset/{}</a>\n",
    "    '''.format(feature['properties']['datasetID'], feature['properties']['datasetID'])\n",
    "\n",
    "geo_json.on_click(update_html)\n",
    "\n",
    "#add minimap\n",
    "#minimap = Map(\n",
    "#    zoom_control=True, attribution_control=False, \n",
    "#    zoom=-2, center=m.center, basemap=basemaps.Esri.WorldImagery \n",
    "#)\n",
    "#minimap.layout.width = '250px'\n",
    "#minimap.layout.height = '200px'\n",
    "#### Changed the datatype of dfg_points, so would need to update this in order for it to work\n",
    "#minimap.add_layer(MarkerCluster(markers=[Marker(location=geolocation.coords[0][::-1]) \\\n",
    "#                                         for geolocation in dfg_points.geometry.unique()]))\n",
    "#link((minimap, 'center'), (m, 'center'))\n",
    "#minimap_control = WidgetControl(widget=minimap, position='bottomleft')\n",
    "\n",
    "#m.add_control(minimap_control)\n",
    "m.add_control(control1)\n",
    "\n",
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:00:38.789055Z",
     "start_time": "2020-07-08T20:00:38.732510Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data = []\n",
    "depth_data = []\n",
    "\n",
    "x_sc = LinearScale()\n",
    "y_sc = LinearScale(reverse=True)\n",
    "\n",
    "line = Lines(x=x_data,\n",
    "             y=depth_data,\n",
    "             scales={'x': x_sc, 'y': y_sc},\n",
    "             colors=['orange', 'red', 'blue', 'black'])\n",
    "\n",
    "ax_x = Axis(label=\"\", scale=x_sc, tick_format='0.1f', num_ticks=5)\n",
    "ax_y = Axis(label=\"\", scale=y_sc,\n",
    "            orientation='vertical', tick_format='0.0f', side='left')\n",
    "\n",
    "figure = Figure(axes=[ax_x, ax_y], marks=[line], animation_duration=300,\n",
    "                layout={'max_height': '270px'}, title=masterParamsMenu.value)\n",
    "\n",
    "\n",
    "#Make the Widgets for selecting parameters\n",
    "paramOptions = [\"\"]\n",
    "style = {'description_width': 'initial'}\n",
    "paramPlotMenu = Dropdown(\n",
    "    options=paramOptions,\n",
    "    description='Parameter to plot:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='80%'),\n",
    "    continuous_update=False,\n",
    "    value=\"\",\n",
    "    style=style\n",
    ")\n",
    "\n",
    "depthOptions = [\"\"]\n",
    "style = {'description_width': 'initial'}\n",
    "depthPlotMenu = Dropdown(\n",
    "    options=depthOptions,\n",
    "    description='Depth to plot:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='80%'),\n",
    "    continuous_update=False,\n",
    "    value=\"\",\n",
    "    style=style\n",
    ")\n",
    "\n",
    "figureDisplay = VBox([figure, paramPlotMenu, depthPlotMenu])\n",
    "#figureDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:01:00.515891Z",
     "start_time": "2020-07-08T20:01:00.499263Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_figure(datasetID, dfp_paramType, gb_dfp_sub_point):\n",
    "    \n",
    "    paramPlotMenu.options = dfp_paramType[\"parameterName\"].loc[dfp_paramType[\"parameterType\"] == \"parameter\"].unique()\n",
    "    depthPlotMenu.options = dfp_paramType[\"parameterName\"].loc[dfp_paramType[\"parameterType\"] == \"depth\"].unique()\n",
    "        \n",
    "    def paramSelect_changed(change):\n",
    "        if change.new != change.old:\n",
    "            paramPlotMenu.value = change.new\n",
    "    \n",
    "    \n",
    "    def depthSelect_changed(change):\n",
    "        if change.new != change.old:\n",
    "            depthPlotMenu.value = change.new\n",
    "    \n",
    "    paramPlotMenu.observe(paramSelect_changed, names='value')\n",
    "    depthPlotMenu.observe(depthSelect_changed, names='value')\n",
    "\n",
    "    parameter = gb_dfp_sub_point[paramPlotMenu.value].dropna().values\n",
    "    depth = gb_dfp_sub_point[depthPlotMenu.value].dropna().values\n",
    "    if len(parameter) == len(depth): #Need at least 2 points for a depth profile\n",
    "        line.x = parameter\n",
    "        line.y = depth\n",
    "        figure.title = paramPlotMenu.value\n",
    "        ax_x.label = dfp_paramType[\"unit\"].loc[dfp_paramType[\"parameterName\"] == paramPlotMenu.value].to_string(index=False)\n",
    "        ax_y.label = dfp_paramType[\"unit\"].loc[dfp_paramType[\"parameterName\"] == depthPlotMenu.value].to_string(index=False)\n",
    "    else:\n",
    "        figure.title = \"Incompatible parameter & depth\"\n",
    "        line.x = [0]\n",
    "        line.y = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:01:26.167475Z",
     "start_time": "2020-07-08T20:01:26.159446Z"
    }
   },
   "outputs": [],
   "source": [
    "widget_control1 = WidgetControl(widget=figureDisplay, position='topright')\n",
    "m.add_control(widget_control1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:02:17.110008Z",
     "start_time": "2020-07-08T20:02:17.101731Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_on_click(event, feature, **kwargs):\n",
    "    global datasetID, dfp_paramType, gb_dfp_sub_point\n",
    "    \n",
    "    coordsList = feature[\"geometry\"][\"coordinates\"]\n",
    "\n",
    "    datasetID = feature[\"properties\"][\"datasetID\"]\n",
    "    #point = str('%.5f' % coordsList[1]) + \" \" + str('%.5f' % coordsList[0])\n",
    "    point = str(coordsList[1]) + \" \" + str(coordsList[0])\n",
    "\n",
    "    \n",
    "    dfp_sub = gb_dfp.get_group(str(datasetID))\n",
    "    dfp_paramType = dfp_sub[[\"parameterType\", \"parameterName\", \"unit\"]].drop_duplicates()\n",
    "    \n",
    "    dfp_sub = dfp_sub.drop(columns=[\"unit\", \"parameterType\", \"geometry\", \"datasetID\", \\\n",
    "                                    \"longitude\", \"latitude\"])\n",
    "    #print(dfp_sub)\n",
    "    gb_dfp_sub = dfp_sub.groupby([\"lon_lat\"])\n",
    "    #print(gb_dfp_sub.groups)\n",
    "    gb_dfp_sub_point = gb_dfp_sub.get_group(point).reset_index()\n",
    "    gb_dfp_sub_point = gb_dfp_sub_point.drop(columns=[\"lon_lat\"])\n",
    "    gb_dfp_sub_point = gb_dfp_sub_point.pivot(index=None, columns='parameterName', values=[\"value\"])\n",
    "    gb_dfp_sub_point.columns = gb_dfp_sub_point.columns.droplevel(level=0)\n",
    "    \n",
    "    update_figure(datasetID, dfp_paramType, gb_dfp_sub_point)#add back point\n",
    "\n",
    "geo_json.on_click(plot_on_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T20:02:39.302543Z",
     "start_time": "2020-07-08T20:02:39.266678Z"
    }
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
